{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bbf7aa",
   "metadata": {},
   "source": [
    "Text_Based_Search_Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795d41a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas sentence-transformers scikit-learn fuzzywuzzy python-Levenshtein pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e86464",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d411acf5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "from fuzzywuzzy import process\n",
    "import numpy as np\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "spell = SpellChecker()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "videos = pd.read_csv('videos.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "def stem_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "videos['title'] = videos['title'].apply(clean_text).apply(remove_stopwords).apply(stem_words)\n",
    "videos['description'] = videos['description'].apply(clean_text).apply(remove_stopwords).apply(stem_words)\n",
    "videos['keyword'] = videos['keyword'].apply(clean_text).apply(remove_stopwords).apply(stem_words)\n",
    "\n",
    "videos['tags'] = videos['description'] + ' ' + videos['genre'] + ' ' + videos['keyword']\n",
    "\n",
    "new_videos_data = videos[['id', 'title', 'tags']]\n",
    "\n",
    "new_videos_data = new_videos_data.drop_duplicates(subset='id').dropna(subset=['title', 'tags'])\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(new_videos_data['tags'].tolist(), show_progress_bar=True)\n",
    "\n",
    "similarityv = cosine_similarity(embeddings)\n",
    "joblib.dump(similarityv, 'similarity_matrix.pkl')\n",
    "new_videos_data.to_csv('videos_data.csv', index=False)\n",
    "\n",
    "def preprocess_input(keyword):\n",
    "    keyword = keyword.lower()\n",
    "    keyword = re.sub(r'[^\\w\\s]', '', keyword)\n",
    "    keyword = re.sub(r'\\s+', ' ', keyword).strip()\n",
    "    return keyword\n",
    "\n",
    "def correct_spelling(keyword):\n",
    "    corrected = []\n",
    "    for word in keyword.split():\n",
    "        if spell.unknown([word]):\n",
    "            candidates = spell.candidates(word)\n",
    "            corrected.append(next(iter(candidates), word) if candidates else word)\n",
    "        else:\n",
    "            corrected.append(word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "def recommend_videos(keyword, num_results=10):\n",
    "    similarityv = joblib.load('similarity_matrix.pkl')\n",
    "    new_videos_data = pd.read_csv('videos_data.csv')\n",
    "\n",
    "    keywords = [preprocess_input(k) for k in keyword.split()]\n",
    "    keywords_corrected = [correct_spelling(k) for k in keywords]\n",
    "\n",
    "    filters = [new_videos_data['title'].str.contains(kw, case=False, na=False) |\n",
    "               new_videos_data['tags'].str.contains(kw, case=False, na=False) for kw in keywords_corrected]\n",
    "\n",
    "    combined_filter = filters[0]\n",
    "    for f in filters[1:]:\n",
    "        combined_filter |= f\n",
    "\n",
    "    filtered_videos = new_videos_data[combined_filter]\n",
    "\n",
    "    if filtered_videos.empty:\n",
    "        titles = new_videos_data['title'].tolist()\n",
    "        closest_match = process.extractOne(keyword, titles)\n",
    "        if closest_match[1] < 10:\n",
    "            print(f\"No videos found containing the keyword '{keyword}'.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"No videos found containing the keyword '{keyword}'. Did you mean '{closest_match[0]}'?\")\n",
    "            return recommend_videos(closest_match[0], num_results)\n",
    "\n",
    "    print(f\"Videos containing the keywords '{keyword}':\")\n",
    "\n",
    "    filtered_videos['keyword_match_score'] = filtered_videos.apply(\n",
    "        lambda row: sum(1.5 if kw in row['title'].lower() else 1.0 if kw in row['tags'].lower() else 0 for kw in keywords_corrected), axis=1\n",
    "    )\n",
    "\n",
    "    total_similarity = np.zeros(len(new_videos_data))\n",
    "    for index in filtered_videos.index:\n",
    "        total_similarity[index] = similarityv[index].sum()\n",
    "\n",
    "    filtered_videos['similarity_score'] = filtered_videos.index.map(lambda idx: total_similarity[idx])\n",
    "\n",
    "    filtered_videos = filtered_videos.sort_values(by=['keyword_match_score', 'similarity_score'], ascending=[False, False])\n",
    "\n",
    "    for _, row in filtered_videos.head(num_results).iterrows():\n",
    "        print(f\"ID: {row['id']}, Title: {row['title']} (Keyword Score: {row['keyword_match_score']}, Similarity: {row['similarity_score']:.2f})\")\n",
    "\n",
    "    print(\"\\nAdditional similar videos:\")\n",
    "    distance = sorted(enumerate(total_similarity), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i in distance:\n",
    "        if i[0] not in filtered_videos.index and i[0] < len(new_videos_data):\n",
    "            recommended_video = new_videos_data.iloc[i[0]]\n",
    "            print(f\"ID: {recommended_video['id']}, Title: {recommended_video['title']} (Similarity: {i[1]:.2f})\")\n",
    "\n",
    "recommend_videos(\"ADIPURUSH CELEBRATING VICTORY OF GOOD OVER EVIL Music Label: T-Series\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686701a",
   "metadata": {},
   "source": [
    "TESTING ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37cc15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "from fuzzywuzzy import process\n",
    "import numpy as np\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "videos = pd.read_csv('videos.csv')\n",
    "\n",
    "videos = videos[['id', 'title', 'description', 'keyword', 'genre']]\n",
    "videos['tags'] = videos['description'] + ' ' + videos['genre'] + ' ' + videos['keyword']\n",
    "\n",
    "new_videos_data = videos.drop(columns=['description', 'genre', 'keyword'])\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(new_videos_data['tags'].tolist(), show_progress_bar=True)\n",
    "\n",
    "similarityv = cosine_similarity(embeddings)\n",
    "joblib.dump(similarityv, 'similarity_matrix.pkl')\n",
    "new_videos_data.to_csv('videos_data.csv', index=False)\n",
    "\n",
    "def preprocess_input(keyword):\n",
    "    keyword = keyword.lower()\n",
    "    keyword = re.sub(r'[^\\w\\s]', '', keyword)\n",
    "    keyword = re.sub(r'\\s+', ' ', keyword).strip()\n",
    "    return keyword\n",
    "\n",
    "def correct_spelling(keyword):\n",
    "    corrected = []\n",
    "    for word in keyword.split():\n",
    "        if spell.unknown([word]):\n",
    "            candidates = spell.candidates(word)\n",
    "            corrected.append(next(iter(candidates), word) if candidates else word)\n",
    "        else:\n",
    "            corrected.append(word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "def recommend_videos(keyword, num_results, ground_truth_ids):\n",
    "    similarityv = joblib.load('similarity_matrix.pkl')\n",
    "    new_videos_data = pd.read_csv('videos_data.csv')\n",
    "\n",
    "    keywords = [preprocess_input(k) for k in keyword.split()]\n",
    "    keywords_corrected = [correct_spelling(k) for k in keywords]\n",
    "\n",
    "    filters = [new_videos_data['title'].str.contains(kw, case=False, na=False) |\n",
    "               new_videos_data['tags'].str.contains(kw, case=False, na=False) for kw in keywords_corrected]\n",
    "\n",
    "    combined_filter = filters[0]\n",
    "    for f in filters[1:]:\n",
    "        combined_filter |= f\n",
    "\n",
    "    filtered_videos = new_videos_data[combined_filter]\n",
    "\n",
    "    if filtered_videos.empty:\n",
    "        titles = new_videos_data['title'].tolist()\n",
    "        closest_match = process.extractOne(keyword, titles)\n",
    "        if closest_match[1] < 10:\n",
    "            print(f\"No videos found containing the keyword '{keyword}'.\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"No videos found containing the keyword '{keyword}'. Did you mean '{closest_match[0]}'?\")\n",
    "            return recommend_videos(closest_match[0], num_results, ground_truth_ids)\n",
    "\n",
    "    print(f\"Videos containing the keywords '{keyword}':\")\n",
    "\n",
    "\n",
    "    filtered_videos['keyword_match_score'] = filtered_videos.apply(\n",
    "        lambda row: sum(1.5 if kw in row['title'].lower() else 1.0 if kw in row['tags'].lower() else 0 for kw in keywords_corrected), axis=1\n",
    "    )\n",
    "\n",
    "    total_similarity = np.zeros(len(new_videos_data))\n",
    "\n",
    "    for index in filtered_videos.index:\n",
    "        total_similarity[index] = similarityv[index].sum()\n",
    "\n",
    "    filtered_videos['similarity_score'] = filtered_videos.index.map(lambda idx: total_similarity[idx])\n",
    "\n",
    "    filtered_videos = filtered_videos.sort_values(by=['keyword_match_score', 'similarity_score'], ascending=[False, False])\n",
    "\n",
    "    filtered_videos = filtered_videos.head(num_results)\n",
    "\n",
    "    def evaluate_recommendations(filtered_videos, ground_truth_ids):\n",
    "        recommended_ids = filtered_videos['id'].tolist()\n",
    "\n",
    "        y_true = [1 if vid in ground_truth_ids else 0 for vid in recommended_ids]\n",
    "        y_pred = [1] * len(recommended_ids)\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        return precision, recall, f1\n",
    "\n",
    "    precision, recall, f1 = evaluate_recommendations(filtered_videos, ground_truth_ids)\n",
    "    print(f\"\\nEvaluation Metrics:\\nPrecision: {precision:.2f}\\nRecall: {recall:.2f}\\nF1 Score: {f1:.2f}\")\n",
    "\n",
    "    for _, row in filtered_videos.iterrows():\n",
    "        print(f\"ID: {row['id']}, Title: {row['title']} (Keyword Score: {row['keyword_match_score']}, Similarity: {row['similarity_score']:.2f})\")\n",
    "\n",
    "    print(\"\\nAdditional similar videos:\")\n",
    "    distance = sorted(enumerate(total_similarity), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i in distance:\n",
    "        if i[0] not in filtered_videos.index and i[0] < len(new_videos_data):\n",
    "            recommended_video = new_videos_data.iloc[i[0]]\n",
    "            print(f\"ID: {recommended_video['id']}, Title: {recommended_video['title']} (Similarity: {i[1]:.2f})\")\n",
    "\n",
    "ground_truth_ids = [934772, 934773, 934774, 934775, 934776, 934777, 934778, 934779, 934780, 934781]\n",
    "recommend_videos(\"Telugu songs\", num_results=10, ground_truth_ids=ground_truth_ids)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
